{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TalentCLEF 2025 - Task A: Baseline for Test set\n",
        "\n",
        "In this notebook, we provide the Test Set baseline for TalentCLEF Task A. This document includes downloading the[Task A dataset](https://doi.org/10.5281/zenodo.14002665), applying a multilingual embedding model as a baseline to generate .trec files, which will then be compressed and uploaded to the Codalab platform.\n",
        "\n",
        "\n",
        "-----------------------------\n",
        "TalentCLEF is an initiative to advance Natural Language Processing (NLP) in Human Capital Management (HCM). It aims to create a public benchmark for model evaluation and promote collaboration to develop fair, multilingual, and flexible systems that improve Human Resources (HR) practices across different industries.\n",
        "\n",
        "This shared-task's inaugural edition is part of the [Conference and Labs of the Evaluation Forum (CLEF)](https://clef2025.clef-initiative.eu/index.php?page=Pages/labs.html), scheduled to be held in Madrid in 2025. If you are interested in registering, you can find registration form [here](https://clef2025-labs-registration.dei.unipd.it/).\n",
        "\n",
        "<img src=\"https://github.com/TalentCLEF/talentclef/blob/main/logo_talentclef.png?raw=true\" alt=\"TalentCLEF logo\" width=\"200\"/>\n",
        "<img src=\"https://talentclef.github.io/talentclef/docs/talentclef-2025/workshop/logo_clef_madrid.png\" alt=\"TalentCLEF logo\" width=\"150\"/>\n"
      ],
      "metadata": {
        "id": "gaNgk9E_9UGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "MFu8opclZyxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install codecarbon"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-7_p9a1Lm9CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from codecarbon import EmissionsTracker"
      ],
      "metadata": {
        "id": "WywIsRRiZx4V"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Task A files"
      ],
      "metadata": {
        "id": "od9qXUQUZ4HL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's download the Task A from Zenodo.\n"
      ],
      "metadata": {
        "id": "DPWD0_VUZ7ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download\n",
        "!wget https://zenodo.org/records/15292308/files/TaskA.zip\n",
        "!unzip TaskA.zip -d taskA"
      ],
      "metadata": {
        "id": "nhlaJhL2Z5qt",
        "collapsed": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline"
      ],
      "metadata": {
        "id": "OCxc20a5g8PR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define language directionalities (queries-documents):"
      ],
      "metadata": {
        "id": "e9KSivulhE_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language_pairs = [\"de-de\",\"es-es\",\"en-en\",\"zh-zh\",\"en-es\",\"en-de\"]\n",
        "map_lang = {\"de\":\"german\",\"es\":\"spanish\",\"en\":\"english\",\"zh\":\"chinese\"}"
      ],
      "metadata": {
        "id": "weOOlAlbg_cp"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "The baseline model is [`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)"
      ],
      "metadata": {
        "id": "H0xGXpXhhTsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"]"
      ],
      "metadata": {
        "id": "Oog5M5QwhYLi"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the model and save results:"
      ],
      "metadata": {
        "id": "e4S_G3RWhk4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emissions = {}\n",
        "\n",
        "for model_name in models:\n",
        "  tracker = EmissionsTracker()\n",
        "  tracker.start_task(model_name)\n",
        "  # Download and load embedding model\n",
        "  model = SentenceTransformer(model_name)\n",
        "  for language_pair in language_pairs:\n",
        "    source_lang, target_lang = language_pair.split(\"-\")\n",
        "    source_lang = map_lang[source_lang]\n",
        "    target_lang = map_lang[target_lang]\n",
        "    print(f\"Language of queries: {source_lang}\")\n",
        "    print(f\"Language of corpus elements: {target_lang}\")\n",
        "    # Read queries and corpus elements for the specific language\n",
        "    queries = f\"/content/taskA/test/{source_lang}/queries\"\n",
        "    corpus_elements = f\"/content/taskA/test/{target_lang}/corpus_elements\"\n",
        "    queries = pd.read_csv(queries,sep=\"\\t\")\n",
        "    corpus_elements = pd.read_csv(corpus_elements, sep=\"\\t\")\n",
        "    # Get ids, strings and generate a mapping dictionary for queries\n",
        "    queries_ids = queries.q_id.to_list()\n",
        "    queries_texts = queries.jobtitle.to_list()\n",
        "    map_queries = dict(zip(queries_ids,queries_texts))\n",
        "    # Get ids, strings and generate a mapping dictionary for corpus elements\n",
        "    corpus_ids = corpus_elements.c_id.to_list()\n",
        "    corpus_texts = corpus_elements.jobtitle.to_list()\n",
        "    map_corpus = dict(zip(queries_ids,queries_texts))\n",
        "    # Encode queries and corpus elements with the baseline model.\n",
        "    query_embeddings = model.encode(queries_texts, convert_to_tensor=True)\n",
        "    corpus_embeddings = model.encode(corpus_texts, convert_to_tensor=True)\n",
        "\n",
        "    # Compute similarities between query and corpus element embeddings\n",
        "    similarities = util.cos_sim(query_embeddings, corpus_embeddings).cpu().numpy()\n",
        "\n",
        "    # Process results and prepare output file\n",
        "    results = []\n",
        "    for q_idx, q_id in enumerate(queries_ids):\n",
        "        sorted_indices = np.argsort(-similarities[q_idx])  # Decrease order\n",
        "        for rank, c_idx in enumerate(sorted_indices):\n",
        "            doc_id = corpus_ids[c_idx]\n",
        "            score = similarities[q_idx, c_idx]\n",
        "            results.append(f\"{str(q_id)} Q0 {str(doc_id)} {rank+1} {score:.4f} baseline_model\")\n",
        "\n",
        "    # Save the predictions in a trecfile. Follow the naming guidelines\n",
        "    with open(f\"run_{language_pair}_testbaseline-{model_name.split('/')[1]}.trec\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(results))\n",
        "    pass\n",
        "  emissions[model_name]: float = dict(tracker.stop_task(model_name).values)\n",
        "\n",
        "json.dump(emissions, open(\"./emissions.json\", \"w\"), ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "LaD3JmNZhnYD",
        "collapsed": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip the results that will be uploaded into the [Task A Codabench](https://www.codabench.org/competitions/5842)"
      ],
      "metadata": {
        "id": "E-URiWpRi4dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip taskA_testset_baseline.zip run_*\n",
        "!zip taskA_testset_baseline_emissions.zip emissions.json"
      ],
      "metadata": {
        "id": "qtXvI_o2i3-y"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}