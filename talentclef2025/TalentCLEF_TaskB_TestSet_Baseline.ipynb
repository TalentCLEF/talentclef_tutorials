{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TalentCLEF 2025 - Task B: Baseline for Test set\n",
        "\n",
        "In this notebook, we provide the Test Set baseline for TalentCLEF Task B. This document includes downloading the [Task B dataset](https://doi.org/10.5281/zenodo.14002665), applying an embedding model as a baseline to generate the submission .trec file, which will then be compressed and uploaded to the Codalab platform.\n",
        "\n",
        "\n",
        "-----------------------------\n",
        "TalentCLEF is an initiative to advance Natural Language Processing (NLP) in Human Capital Management (HCM). It aims to create a public benchmark for model evaluation and promote collaboration to develop fair, multilingual, and flexible systems that improve Human Resources (HR) practices across different industries.\n",
        "\n",
        "This shared-task's inaugural edition is part of the [Conference and Labs of the Evaluation Forum (CLEF)](https://clef2025.clef-initiative.eu/index.php?page=Pages/labs.html), scheduled to be held in Madrid in 2025. If you are interested in registering, you can find registration form [here](https://clef2025-labs-registration.dei.unipd.it/).\n",
        "\n",
        "<img src=\"https://github.com/TalentCLEF/talentclef/blob/main/logo_talentclef.png?raw=true\" alt=\"TalentCLEF logo\" width=\"200\"/>\n",
        "<img src=\"https://talentclef.github.io/talentclef/docs/talentclef-2025/workshop/logo_clef_madrid.png\" alt=\"TalentCLEF logo\" width=\"150\"/>\n"
      ],
      "metadata": {
        "id": "4NXz9y-YOxuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "gHTbA4g4b5Na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install codecarbon"
      ],
      "metadata": {
        "id": "cvL1Z1ntvrBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import subprocess\n",
        "from codecarbon import EmissionsTracker"
      ],
      "metadata": {
        "id": "bLytpvDOb6ad"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Task B files"
      ],
      "metadata": {
        "id": "5u2jKkACTFM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's download the Task A and Task B zip files directly from Zenodo.\n",
        "\n"
      ],
      "metadata": {
        "id": "h6dj1eCOTIN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download\n",
        "!wget https://zenodo.org/records/15292308/files/TaskB.zip\n",
        "!unzip TaskB.zip -d taskB"
      ],
      "metadata": {
        "id": "At8D-dYyMJDt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate submission file using the baseline model"
      ],
      "metadata": {
        "id": "FPjKPVf5XagR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load queries and corpus elements in English from the Validation folder:"
      ],
      "metadata": {
        "id": "IcVd8_ogbyeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = \"/content/taskB/test/queries\"\n",
        "corpus_elements = \"/content/taskB/test/corpus_elements\""
      ],
      "metadata": {
        "id": "I5n68HKmXk9M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = pd.read_csv(queries,sep=\"\\t\")\n",
        "corpus_elements = pd.read_csv(corpus_elements, sep=\"\\t\")\n"
      ],
      "metadata": {
        "id": "pRQGDd7CYGPu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform `skill_aliases` column to a list of strings:"
      ],
      "metadata": {
        "id": "1V2kAegcrZM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "corpus_elements[\"skill_aliases\"] = corpus_elements[\"skill_aliases\"].apply(lambda x: ast.literal_eval(x))"
      ],
      "metadata": {
        "id": "8Yr1jIxtoj8V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a mapping dictionary between IDs and texts from query and corpus element strings."
      ],
      "metadata": {
        "id": "dvLGAywHcBGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries_ids = queries.q_id.to_list()\n",
        "queries_texts = queries.jobtitle.to_list()\n",
        "map_queries = dict(zip(queries_ids,queries_texts))"
      ],
      "metadata": {
        "id": "MAoY01hXoSUz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before creating a mapping dictionary of texts to corpus_ids, explode the `skill_aliases` column:"
      ],
      "metadata": {
        "id": "3ke4L-amrgqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_aliases_df = corpus_elements.explode(\"skill_aliases\")"
      ],
      "metadata": {
        "id": "egGCX2E_x81O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_ids = list_aliases_df.c_id.to_list()\n",
        "corpus_texts = list_aliases_df.skill_aliases.to_list()\n",
        "map_corpus = dict(zip(corpus_texts,corpus_ids))"
      ],
      "metadata": {
        "id": "pRCjRJd2cGCx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load simple embedding model:"
      ],
      "metadata": {
        "id": "sScTIy47cMiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OclD_jKcYSnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tJLf_cKvTEa"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 11,
      "source": [
        "tracker = EmissionsTracker()\n",
        "tracker.start_task(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode queries and corpus elements:"
      ],
      "metadata": {
        "id": "rOWdNfw6cQUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_embeddings = model.encode(queries_texts, convert_to_tensor=True)\n",
        "corpus_embeddings = model.encode(corpus_texts, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "PhkWx-RsYPMC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute similarities"
      ],
      "metadata": {
        "id": "8BG1vQK3cUyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = util.cos_sim(query_embeddings, corpus_embeddings).cpu().numpy()\n",
        "emissions = tracker.stop_task(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "yMvxZ9_dY2le"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare submission file"
      ],
      "metadata": {
        "id": "36quRAvPcZiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The submissions must follow the TREC Run File format, including headers in the output file. This means that the fle have 6 space-spearated columns per line, with following information:\n",
        "\n",
        "- q_id: Query ID.\n",
        "- Q0: A constant identifier, usually \"Q0\".\n",
        "- doc_id: ID of the retrieved document.\n",
        "- rank: Position of the document in the ranking.\n",
        "- score: Relevance score assigned by the model.\n",
        "- tag: Experiment name"
      ],
      "metadata": {
        "id": "gBZIHr6Occh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "results = []\n",
        "results_name = []\n",
        "\n",
        "for q_idx, q_id in enumerate(queries_ids):\n",
        "    sorted_indices = np.argsort(-similarities[q_idx])\n",
        "    used_doc_ids = set()\n",
        "    rank_counter = 0\n",
        "    for c_idx in sorted_indices:  # Consider the full list.\n",
        "        doc_id = corpus_ids[c_idx]\n",
        "        # If doc_id was already processed, go to the next one.\n",
        "        if doc_id in used_doc_ids:\n",
        "            continue\n",
        "        used_doc_ids.add(doc_id)\n",
        "        rank_counter += 1\n",
        "\n",
        "        query_name = map_queries[q_id]\n",
        "        doc_name = corpus_texts[c_idx]\n",
        "        score = similarities[q_idx, c_idx]\n",
        "\n",
        "        results.append(f\"{q_id} Q0 {doc_id} {rank_counter} {score:.4f} baseline_model\")\n",
        "        results_name.append(f\"{query_name} Q0 {doc_name} {rank_counter} {score:.4f} baseline_model\")"
      ],
      "metadata": {
        "id": "eNZ_KNAbZDWw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the list as a file:"
      ],
      "metadata": {
        "id": "7AGaIVV9dxYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"run_testset_baseline_taskB.trec\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(results))"
      ],
      "metadata": {
        "id": "eRnSEkckdrWA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "json.dump(dict(emissions.values), open(\"./emissions.json\", \"w\"), ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "wswJf_zrwNSH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip the results that will be uploaded into the [Task B Codabench](https://www.codabench.org/competitions/7059)"
      ],
      "metadata": {
        "id": "E-URiWpRi4dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip taskB_testset_baseline.zip run_*\n",
        "!zip taskB_testset_baseline_emissions.zip emissions.json"
      ],
      "metadata": {
        "id": "qtXvI_o2i3-y"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}